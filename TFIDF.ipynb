{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8fd13a2-63b6-4e93-b724-62deb063334a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "959717b5-214a-47a2-bdc2-3e51ef79f211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our sample documents\n",
      "Doc0:The cat sat on the mat\n",
      "Doc1:The dog run in the park\n",
      "Doc2:Cats and dogs are pets\n",
      "Doc3:I love my pet cat\n",
      "Doc4:The park has many trees\n"
     ]
    }
   ],
   "source": [
    "#step 1: sample document setup\n",
    "#simple documents\n",
    "sample_documents = [\n",
    "    \"The cat sat on the mat\",\n",
    "    \"The dog run in the park\",\n",
    "    \"Cats and dogs are pets\",\n",
    "    \"I love my pet cat\",\n",
    "    \"The park has many trees\"\n",
    "]\n",
    "\n",
    "print(\"Our sample documents\")\n",
    "for i, doc in enumerate(sample_documents):\n",
    "    print(f\"Doc{i}:{doc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e778f77-e1fa-4d75-a61c-c34953e5a9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Step 2: Text Preprocessing\n",
      "==================================================\n",
      "Original:The cat sat on the mat\n",
      "Processed: ['the', 'cat', 'sat', 'on', 'the', 'mat']\n",
      "\n",
      "All processed documents:\n",
      "Doc 0: ['the', 'cat', 'sat', 'on', 'the', 'mat']\n",
      "Doc 1: ['the', 'dog', 'run', 'in', 'the', 'park']\n",
      "Doc 2: ['cats', 'and', 'dogs', 'are', 'pets']\n",
      "Doc 3: ['i', 'love', 'my', 'pet', 'cat']\n",
      "Doc 4: ['the', 'park', 'has', 'many', 'trees']\n"
     ]
    }
   ],
   "source": [
    "#step 2: text pre-processing\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Clean and tokenize text\n",
    "    - Convert to lowercase\n",
    "    - Remove punctuation\n",
    "    - split into words\n",
    "    \"\"\"\n",
    "    #convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    #remove punctuation and splits into words\n",
    "    words = re.findall(r'\\b[a-z]+\\b', text)\n",
    "\n",
    "    return words\n",
    "\n",
    "# test pre-processing\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Step 2: Text Preprocessing\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "test_doc = sample_documents[0]\n",
    "processed = preprocess_text(test_doc)\n",
    "print(f\"Original:{test_doc}\")\n",
    "print(f\"Processed: {processed}\" )\n",
    "\n",
    "#process all documents\n",
    "processed_docs = [preprocess_text(doc) for doc in sample_documents]\n",
    "print(f\"\\nAll processed documents:\")\n",
    "for i, doc in enumerate(processed_docs):\n",
    "    print(f\"Doc {i}: {doc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a49e53d2-2bd8-4a6a-8215-7ae34953c2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Step 3: Build vocabulary\n",
      "==================================================\n",
      "Vocabulary (21words): ['and', 'are', 'cat', 'cats', 'dog', 'dogs', 'has', 'i', 'in', 'love', 'many', 'mat', 'my', 'on', 'park', 'pet', 'pets', 'run', 'sat', 'the', 'trees']\n"
     ]
    }
   ],
   "source": [
    "#step 3: build vocabulary\n",
    "def build_vocabulary(processed_docs):\n",
    "    \"\"\"\n",
    "    Create a vocabulary/unique words from all documents\n",
    "    \"\"\"\n",
    "    vocab = set()\n",
    "    for doc in processed_docs:\n",
    "        vocab.update(doc)\n",
    "    return sorted(list(vocab)) \n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Step 3: Build vocabulary\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "vocabulary = build_vocabulary(processed_docs)\n",
    "print(f\"Vocabulary ({len(vocabulary)}words): {vocabulary}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5440d503-7a5f-4f6e-a29b-0cd43e8056fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "step 4: calculate term frequency (TF)\n",
      "==================================================\n",
      "\n",
      "Doc 0 TF Scores:\n",
      "cat:0.167\n",
      "mat:0.167\n",
      "on:0.167\n",
      "sat:0.167\n",
      "the:0.333\n",
      "\n",
      "Doc 1 TF Scores:\n",
      "dog:0.167\n",
      "in:0.167\n",
      "park:0.167\n",
      "run:0.167\n",
      "the:0.333\n",
      "\n",
      "Doc 2 TF Scores:\n",
      "and:0.200\n",
      "are:0.200\n",
      "cats:0.200\n",
      "dogs:0.200\n",
      "pets:0.200\n",
      "\n",
      "Doc 3 TF Scores:\n",
      "cat:0.200\n",
      "i:0.200\n",
      "love:0.200\n",
      "my:0.200\n",
      "pet:0.200\n",
      "\n",
      "Doc 4 TF Scores:\n",
      "has:0.200\n",
      "many:0.200\n",
      "park:0.200\n",
      "the:0.200\n",
      "trees:0.200\n"
     ]
    }
   ],
   "source": [
    "#step 4 : calculate term frequency\n",
    "def calculate_tf(doc_words, vocabulary):\n",
    "    \"\"\"\n",
    "    calculate term frequency for a single document\n",
    "    TF = (word count in document) / (total words in document)\n",
    "    \"\"\"\n",
    "    tf_dict = {}\n",
    "    doc_length = len(doc_words)\n",
    "    word_counts = Counter(doc_words)\n",
    "\n",
    "    for word in vocabulary:\n",
    "        tf_dict[word] = word_counts[word] / doc_length\n",
    "\n",
    "    return tf_dict\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"step 4: calculate term frequency (TF)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "tf_docs = []\n",
    "for i, doc in enumerate(processed_docs):\n",
    "    tf = calculate_tf(doc,vocabulary)\n",
    "    tf_docs.append(tf)\n",
    "    print(f\"\\nDoc {i} TF Scores:\")\n",
    "\n",
    "    #show only non-zero TF Scores for clarity\n",
    "\n",
    "    non_zero_tf = {word: score for word, score in tf.items() if score > 0}\n",
    "    for word, score in non_zero_tf.items():\n",
    "        print(f\"{word}:{score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eacfc0ed-339b-4003-a805-464bb920aac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "step 5: calculating inverse document frequency(IDF)\n",
      "==================================================\n",
      "IDF Scores:\n",
      "and: 1.609 (appears in 1/5 docs)\n",
      "are: 1.609 (appears in 1/5 docs)\n",
      "cat: 0.916 (appears in 2/5 docs)\n",
      "cats: 1.609 (appears in 1/5 docs)\n",
      "dog: 1.609 (appears in 1/5 docs)\n",
      "dogs: 1.609 (appears in 1/5 docs)\n",
      "has: 1.609 (appears in 1/5 docs)\n",
      "i: 1.609 (appears in 1/5 docs)\n",
      "in: 1.609 (appears in 1/5 docs)\n",
      "love: 1.609 (appears in 1/5 docs)\n",
      "many: 1.609 (appears in 1/5 docs)\n",
      "mat: 1.609 (appears in 1/5 docs)\n",
      "my: 1.609 (appears in 1/5 docs)\n",
      "on: 1.609 (appears in 1/5 docs)\n",
      "park: 0.916 (appears in 2/5 docs)\n",
      "pet: 1.609 (appears in 1/5 docs)\n",
      "pets: 1.609 (appears in 1/5 docs)\n",
      "run: 1.609 (appears in 1/5 docs)\n",
      "sat: 1.609 (appears in 1/5 docs)\n",
      "the: 0.511 (appears in 3/5 docs)\n",
      "trees: 1.609 (appears in 1/5 docs)\n"
     ]
    }
   ],
   "source": [
    "#step 5: calculate inverse document frequency\n",
    "def calculate_idf(processed_docs, vocabulary):\n",
    "    \"\"\"\n",
    "    Calculate IDF for each word in vocabulary\n",
    "    IDF = log(total documents / documents containing the word)\n",
    "    \"\"\"\n",
    "\n",
    "    idf_dict = {}\n",
    "    total_docs = len(processed_docs)\n",
    "\n",
    "    for word in vocabulary:\n",
    "        # count how many documents contain this word\n",
    "        docs_containing_word = sum(1 for doc in processed_docs if word in doc)\n",
    "\n",
    "        # calculate idf\n",
    "        idf_dict[word] = math.log(total_docs / docs_containing_word)\n",
    "\n",
    "    return idf_dict\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"step 5: calculating inverse document frequency(IDF)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "idf_scores = calculate_idf(processed_docs, vocabulary)\n",
    "print(\"IDF Scores:\")\n",
    "for word, score in idf_scores.items():\n",
    "    docs_with_word = sum(1 for doc in processed_docs if word in doc)\n",
    "    print(f\"{word}: {score:.3f} (appears in {docs_with_word}/{len(processed_docs)} docs)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2bd7704-d0f5-4e0f-bf06-c211444aa129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Step 6: Calculate TF-IDF scores\n",
      "==================================================\n",
      "TF-IDF Matrix:\n",
      "        and    are    cat   cats    dog   dogs    has      i     in   love  \\\n",
      "Doc0  0.000  0.000  0.153  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
      "Doc1  0.000  0.000  0.000  0.000  0.268  0.000  0.000  0.000  0.268  0.000   \n",
      "Doc2  0.322  0.322  0.000  0.322  0.000  0.322  0.000  0.000  0.000  0.000   \n",
      "Doc3  0.000  0.000  0.183  0.000  0.000  0.000  0.000  0.322  0.000  0.322   \n",
      "Doc4  0.000  0.000  0.000  0.000  0.000  0.000  0.322  0.000  0.000  0.000   \n",
      "\n",
      "      ...    mat     my     on   park    pet   pets    run    sat    the  \\\n",
      "Doc0  ...  0.268  0.000  0.268  0.000  0.000  0.000  0.000  0.268  0.170   \n",
      "Doc1  ...  0.000  0.000  0.000  0.153  0.000  0.000  0.268  0.000  0.170   \n",
      "Doc2  ...  0.000  0.000  0.000  0.000  0.000  0.322  0.000  0.000  0.000   \n",
      "Doc3  ...  0.000  0.322  0.000  0.000  0.322  0.000  0.000  0.000  0.000   \n",
      "Doc4  ...  0.000  0.000  0.000  0.183  0.000  0.000  0.000  0.000  0.102   \n",
      "\n",
      "      trees  \n",
      "Doc0  0.000  \n",
      "Doc1  0.000  \n",
      "Doc2  0.000  \n",
      "Doc3  0.000  \n",
      "Doc4  0.322  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "#step 6: calculate tf-idf scores\n",
    "def calculate_tfidf(tf_docs, idf_scores, vocabulary):\n",
    "    \"\"\"\n",
    "    Calculate TF-IDF = TF x IDF for all documents\n",
    "    \"\"\"\n",
    "    tfidf_docs = []\n",
    "\n",
    "    for tf_doc in tf_docs:\n",
    "        tfidf_dict = {}\n",
    "        \n",
    "        for word in vocabulary:\n",
    "            tfidf_dict[word] = tf_doc[word] * idf_scores[word]\n",
    "        tfidf_docs.append(tfidf_dict)\n",
    "\n",
    "    return tfidf_docs\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Step 6: Calculate TF-IDF scores\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "tfidf_docs = calculate_tfidf(tf_docs,idf_scores, vocabulary)\n",
    "\n",
    "# Display tf-idf scores in a table\n",
    "tfidf_df = pd.DataFrame(tfidf_docs)\n",
    "tfidf_df.index = [f\"Doc{i}\" for i in range(len(sample_documents))]\n",
    "print(\"TF-IDF Matrix:\")\n",
    "print(tfidf_df.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40ec016a-444f-4315-9609-d76ea22e18fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "STEP 7: Document Similarity Search\n",
      "==================================================\n",
      "Search query: 'cats and dogs'\n",
      "\n",
      "Search results (most similar first):\n",
      "1. Doc2: 'Cats and dogs are pets' (similarity:0.775)\n",
      "2. Doc0: 'The cat sat on the mat' (similarity:0.000)\n",
      "3. Doc1: 'The dog run in the park' (similarity:0.000)\n"
     ]
    }
   ],
   "source": [
    "# step 7: Document similarity search\n",
    "\n",
    "def cosine_similarity_manual(vec1, vec2):\n",
    "    \"\"\"\n",
    "    calculate cosine similarity between two vectors\n",
    "    \"\"\"\n",
    "\n",
    "    dot_product = sum(a * b for a, b in zip (vec1, vec2) )\n",
    "    magnitude1 = math.sqrt(sum(a * a for a in vec1))\n",
    "    magnitude2 = math.sqrt(sum(b * b for b in vec2))\n",
    "\n",
    "    if magnitude1 == 0 or magnitude2 == 0:\n",
    "        return 0\n",
    "\n",
    "    return dot_product / (magnitude1 * magnitude2)\n",
    "\n",
    "def search_documents(query, sample_documents, tfidf_docs, vocabulary, idf_scores):\n",
    "    \"\"\"\n",
    "    Search for most similar documents to a query\n",
    "    \"\"\"\n",
    "\n",
    "    # process query\n",
    "    query_words = preprocess_text(query)\n",
    "\n",
    "    # calculate query TF-IDF\n",
    "    query_tf = calculate_tf(query_words, vocabulary)\n",
    "    query_tfidf = {word:query_tf[word] * idf_scores[word] for word in vocabulary}\n",
    "\n",
    "    # convert to vectors\n",
    "    query_vector = [query_tfidf[word] for word in vocabulary]\n",
    "\n",
    "    # calculate similarities\n",
    "    similarities = []\n",
    "    for i, doc_tfidf in enumerate(tfidf_docs):\n",
    "        doc_vector = [doc_tfidf[word] for word in vocabulary]\n",
    "        similarity = cosine_similarity_manual(query_vector, doc_vector)\n",
    "        similarities.append((i,similarity))\n",
    "\n",
    "    # sort by similarity (highest first)\n",
    "    similarities.sort(key = lambda x: x[1], reverse = True)\n",
    "\n",
    "    return similarities\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"STEP 7: Document Similarity Search\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Test search\n",
    "test_query = \"cats and dogs\"\n",
    "print(f\"Search query: '{test_query}'\")\n",
    "print(\"\\nSearch results (most similar first):\")\n",
    "\n",
    "results = search_documents(test_query, sample_documents, tfidf_docs, vocabulary, idf_scores)\n",
    "\n",
    "for rank, (doc_idx, similarity) in enumerate(results[:3],1):\n",
    "    print(f\"{rank}. Doc{doc_idx}: '{sample_documents[doc_idx]}' (similarity:{similarity:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2e50ca1-4320-4414-8cc4-fd51bad80cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "STEP 8: Validation with Scikit-Learn\n",
      "==================================================\n",
      "Scikit-Learn TF-IDF Matrix:\n",
      "         and    are    cat   cats    dog   dogs    has      i     in   love  \\\n",
      "Doc_0  0.000  0.000  0.346  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
      "Doc_1  0.000  0.000  0.000  0.000  0.429  0.000  0.000  0.000  0.429  0.000   \n",
      "Doc_2  0.447  0.447  0.000  0.447  0.000  0.447  0.000  0.000  0.000  0.000   \n",
      "Doc_3  0.000  0.000  0.374  0.000  0.000  0.000  0.000  0.464  0.000  0.464   \n",
      "Doc_4  0.000  0.000  0.000  0.000  0.000  0.000  0.494  0.000  0.000  0.000   \n",
      "\n",
      "       ...    mat     my     on   park    pet   pets    run    sat    the  \\\n",
      "Doc_0  ...  0.429  0.000  0.429  0.000  0.000  0.000  0.000  0.429  0.574   \n",
      "Doc_1  ...  0.000  0.000  0.000  0.346  0.000  0.000  0.429  0.000  0.574   \n",
      "Doc_2  ...  0.000  0.000  0.000  0.000  0.000  0.447  0.000  0.000  0.000   \n",
      "Doc_3  ...  0.000  0.464  0.000  0.000  0.464  0.000  0.000  0.000  0.000   \n",
      "Doc_4  ...  0.000  0.000  0.000  0.398  0.000  0.000  0.000  0.000  0.331   \n",
      "\n",
      "       trees  \n",
      "Doc_0  0.000  \n",
      "Doc_1  0.000  \n",
      "Doc_2  0.000  \n",
      "Doc_3  0.000  \n",
      "Doc_4  0.494  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "\n",
      "Comparison:\n",
      "Our Vocbulary size: 21\n",
      "Scikit-learn vocabulary size: 21\n",
      "Vocabularies match: True\n"
     ]
    }
   ],
   "source": [
    "# step 8: Compare with scikit-learn\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"STEP 8: Validation with Scikit-Learn\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# use scikit-learn for comparison\n",
    "vectorizer = TfidfVectorizer(lowercase = True, token_pattern = r'\\b[a-z]+\\b')\n",
    "sklearn_tfidf = vectorizer.fit_transform(sample_documents)\n",
    "sklearn_feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "#convert to dataframe for comparison\n",
    "sklearn_df = pd.DataFrame(sklearn_tfidf.toarray(), \n",
    "                          columns=sklearn_feature_names, \n",
    "                          index = [f\"Doc_{i}\" for i in range(len(sample_documents))])\n",
    "\n",
    "print(\"Scikit-Learn TF-IDF Matrix:\")\n",
    "print(sklearn_df.round(3))\n",
    "\n",
    "print(f\"\\nComparison:\")\n",
    "print(f\"Our Vocbulary size: {len(vocabulary)}\")\n",
    "print(f\"Scikit-learn vocabulary size: {len(sklearn_feature_names)}\")\n",
    "print(f\"Vocabularies match: {set(vocabulary) == set(sklearn_feature_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ffe35835-b954-4884-913c-3a5535f17586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "STEP 9: Complete TF-IDF Class Usage\n",
      "==================================================\n",
      "TF-IDF Matrix shape: (5, 21)\n",
      "Vocabulary size: 21\n",
      "\n",
      "Search results for 'cats and dogs':\n",
      "1. 'Cats and dogs are pets' (similarity:0.775)\n",
      "2. 'The cat sat on the mat' (similarity:0.000)\n",
      "3. 'The dog run in the park' (similarity:0.000)\n"
     ]
    }
   ],
   "source": [
    "# step 9: complete tf-idf class\n",
    "\n",
    "\n",
    "class SimpleTFIDF:\n",
    "    \"\"\"\n",
    "    A simple tfidf implementation from scratch\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.vocabulary = []\n",
    "        self.idf_scores = {}\n",
    "        self.documents  = []\n",
    "\n",
    "    def fit(self,documents):\n",
    "        \"\"\"Train the tf-idf model on documents\"\"\"\n",
    "\n",
    "        self.documents = documents\n",
    "        processed_docs = [preprocess_text(doc) for doc in documents]\n",
    "        self.vocabulary = build_vocabulary(processed_docs)\n",
    "        self.idf_scores = calculate_idf(processed_docs, self.vocabulary)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self,documents):\n",
    "        \"\"\"transform documents to tf-idf vectors\"\"\"\n",
    "\n",
    "        processed_docs = [preprocess_text(doc) for doc in documents]\n",
    "        tf_docs = [calculate_tf(doc, self.vocabulary) for doc in processed_docs]\n",
    "        tfidf_docs = calculate_tfidf(tf_docs, self.idf_scores, self.vocabulary)\n",
    "\n",
    "        \"\"\"convert to matrix form\"\"\"\n",
    "\n",
    "        matrix = []\n",
    "        for tfidf_doc in tfidf_docs:\n",
    "            vector = [tfidf_doc[word] for word in self.vocabulary]\n",
    "            matrix.append(vector)\n",
    "\n",
    "        return np.array(matrix)\n",
    "\n",
    "    def fit_transform(self, documents):\n",
    "        \"\"\"fit and transform in one step\"\"\"\n",
    "        return self.fit(documents).transform(documents)\n",
    "\n",
    "    def search(self, query, top_k =3):\n",
    "        \"\"\"search for most similar documents\"\"\"\n",
    "        query_vector = self.transform([query])[0]\n",
    "        doc_vectors = self.transform(self.documents)\n",
    "\n",
    "        similarities = []\n",
    "        for i, doc_vector in enumerate(doc_vectors):\n",
    "            similarity = cosine_similarity_manual(query_vector, doc_vector)\n",
    "            similarities.append((i,similarity, self.documents[i]))\n",
    "\n",
    "        similarities.sort(key=lambda x:x[1], reverse=True)\n",
    "        return similarities[:top_k]\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"STEP 9: Complete TF-IDF Class Usage\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# test the complete tf-idf class\n",
    "tfidf_model = SimpleTFIDF()\n",
    "tfidf_matrix = tfidf_model.fit_transform(sample_documents)\n",
    "\n",
    "print(\"TF-IDF Matrix shape:\", tfidf_matrix.shape)\n",
    "print(\"Vocabulary size:\", len(tfidf_model.vocabulary))\n",
    "\n",
    "# test search\n",
    "\n",
    "print(f\"\\nSearch results for '{test_query}':\")\n",
    "search_results = tfidf_model.search(test_query)\n",
    "for rank, (doc_idx, similarity, document) in enumerate (search_results, 1):\n",
    "    print(f\"{rank}. '{document}' (similarity:{similarity:.3f})\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865a0855-7708-4441-b39f-fc434b5d823d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
